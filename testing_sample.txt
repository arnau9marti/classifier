SELECTION OF RESOURCES TO TEST

In the logistic industry, IoT applications are considered as cheap solutions for variety of use cases, and could be easily combined with machine learning and artificial intelligent in order to develop smart maintenance and supervision models for the industrial assets. Especially, in the contact with cooperation partners in the logistic industry, we found that the behavior data of forklifts is full of value, which not only indicates directly the working status of a forklift (e.g. loading, unloading, normal driving, harmful vibration etc.), but is also possible to be further used for analyzing high level KPIs. For instance, the analyzing of forklift workload is valuable to arrange assets and forecast demand, as well as for predictive maintenance. This is an IoT solution in combination with machine learning algorithm for the logistic industry, aiming at analyzing daily behaviors of the forklifts. Those classified behavior data can be use by other IoT applications for further analysis, for example analysis functions of RIOTANA (Real-time IoT Analytics) by Fraunhofer ISST. We collect real motion sensor data from forklifts and develop machine learning algorithms to recognize the behaviors.

LioNets on Time Series (LioNets technique applied to the Turbofan Engine Degradation Simulation dataset) LioNets is a methodology on providing explanations for a neural network's decisions, in a local scope, through a process that actively takes into consideration the neural network's architecture on creating an instance's neighbourhood, that assures the adjacency among the generated neighbours and the instance. LioNets first presented in the Asset: “LioNets: Local Interpretations Of Neural Networks through Penultimate Layer Decoding” (https://www.ai4eu.eu/resource/lionets-local-interpretations-neural-networks-through-penultimate-layer-decoding) In this asset, the code of LioNets (v2.0) is supporting two python notebooks, which present two ways to interpret a binary classifier and a remaining useful lifetime predictor on the Turbofan Engine Degradation Simulation Dataset (https://data.nasa.gov/dataset/Turbofan-engine-degradation-simulation-data-set/vrks-gjie). This work is an essential setup, to be prepared for the AI4Robotics dataset. When this dataset is to be published, it will also be adapted to the exact same methodology presented in this asset. The original GitHub repository is the following:

Classification of documents has usually been performed following two main approaches: 1) analyse the textual content in order to extract text-based features; and/or 2) design a set of visual features to be extracted from the image of a document. These features were then used to train a machine learning model aiming to classify the documents under analysis. The recent advances in deep learning introduced the possibility to learn both the features and the classifier directly from the data improving the final performance with respect to classical handcrafted solutions. This is a computer vision tool specifically designed to automate the classification process of document images; currently the images can be classified in seven possible classes. The proposed solution exploits a convolutional neural network pre-trained on the ImageNet dataset. In particular, the architecture used is ResNet50, a very deep convolutional neural network which exploits residual connections to improve the final training performance. Transfer learning is then applied in order to leverage knowledge previously learnt from the visual objects’ domain and “transfer it” to a new domain (e.g., document images). This is obtained by fine-tuning the pre-trained network on a usually smaller dataset from the new domain. The fine-tuning process requires to substitute the existing classification layer with a new one in order to adapt the network to the new task. Then a training is performed, using the images from the new domain, so as to slightly modify the existing weights and obtain a new set of features which is able to better discriminate the images of the new task.

Petri Net Plans (PNP) is a formalism for high level description of complex plans (i.e., set of actions interacting in a complex way). PNP is useful to program cognitive agents (such as robots, videogame agents, multi-robot/multi-agent systems, etc.). PNPs are inspired to languages for reasoning about actions, yet they are more expressive than most of them, offering a full fledged set of operators for dealing with non-instantaneous actions, sensing actions, action failures, concurrent actions and cooperation in a multi agent context. PNPs include also choice operators used for non-deterministic execution and for learning in the plan space through a Reinforcement Learning algorithm. PNPs are more expressive than Finite State Machines (FSM) and allow for automatic plan analysis, which can provide formal guarantees on the performance of the plans. Execution of PNPs is extremely efficient and allows the design of real-time pro-active and reactive behaviors.

Software solution based on Convolutional Neural Network for image analysis and time series analysis for detection and prediction of road defects. AI based computer vision solution is developed for image analysis with a proper camera mounted on a car. Time series will be developed for data analysis to predict defect dimensions and their occurrence.

In the context of education, it is increasingly common that students spend some time doing practical work in a company as part of their curriculum. This work is sometimes remunerated: companies benefit from this program as they get motivated students that will work for reduced wages, and students benefit from a first contact with the labour market. It has been found that the employability of students at the end of their studies increases thanks to these internships. Nowadays, education authorities match students with companies mostly by hand. This algorithms performs this matching process by solving a combinatorial optimization problem. It is based on an anytime heuristic algorithm that solves the combinatorial problem.

The method of LORE does not make any assumption on the classifier that is used for labeling. The approach used by LORE exploits the exploration of a neighborhood of the input instance, based on a genetic algorithm to generate synthetic instances, to learn a local transparent model, which can be interpreted locally by the analyst.

SUMO/RL implements a pipeline with a traffic simulator of the city of Trondheim, Norway, and a reinforcement learning autonomous agent that learns and implements traffic control policies with the goal of minimizing the number of pollution peaks above a given threshold. Each component can be ran stand alone.

Sextant is a web based and mobile ready platform for visualizing, exploring and interacting with linked geospatial data. The core feature of Sextant is the ability to create thematic maps by combining geospatial and temporal information that exists in a number of heterogeneous data sources, ranging from standard SPARQL endpoints, to SPARQL endpoints following the standard GeoSPARQL defined by the Open Geospatial Consortium (OGC), or well-adopted geospatial file formats, like KML, GML and GeoTIFF.

The EMLlib allows one to embed a pre-trained Machine Learning model, by encoding its structure using variables and constraints. This is useful when dealing with optimization problems over complex real world systems (e.g. in prescriptive analytics), for ML model verification, and for generating counterexamples.
